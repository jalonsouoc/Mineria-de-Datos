---
title: 'Minería de datos: PRA1 - Selección y preparación de un juego de datos'
author: "Autor: Jorge Alonso Hernández"
date: "Noviembre 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación

En esta práctica abordamos un caso real de minería de datos donde tenemos que poner en juego todos los conceptos trabajados en la asignatura. Hay que trabajar todo el ciclo de vida del proyecto, desde el objetivo del proyecto hasta la implementación del conocimiento encontrado, pasando por la preparación, limpieza de los datos, conocimiento de los datos, generación del modelo, interpretación y evaluación. La práctica la dividiremos en dos partes. En esta primera parte (PRA1), abordaremos las primeras fases del proceso, desde los objetivos hasta la preparación de los datos, y en la segunda parte (PRA2) seguiremos con el resto del proceso.


## Objetivos

El objetivo global de esta primera parte de la práctica (PRA1) consiste en seleccionar uno o varios juegos de datos, y realizar las tareas de **preparación y análisis exploratorio** con el objetivo de disponer de datos listos para después, en la segunda parte (PRA2),  **aplicar algoritmos** de clustering, regresión o clasificación, demostrando la correcta asimilación de todos los aspectos trabajados durante el semestre.  

******
# Descripción de la PRA a realizar
******

La analítica de datos como actividad profesional, se sustenta en 3 ejes fundamentales. Uno de ellos es el profundo **conocimiento** que deberíamos tener **del problema** al que tratamos de dar respuestas mediante los estudios analíticos. Todo estudio analítico debe nacer de una necesidad por parte del **negocio** o de una necesidad de toma de decisiones basada en los datos y que resolveremos siguiendo las buenas prácticas basadas en la minería de datos. El otro aspecto importante es sin duda las **capacidades analíticas** que seamos capaces de desplegar y en este sentido, las dos prácticas de esta asignatura pretenden que el estudiante realice un recorrido sólido por este segundo eje. El tercer eje son los **datos**. Las necesidades del negocio deben concretarse con preguntas analíticas que sea posible responder a partir de los datos de que disponemos. La tarea de analizar los datos es sin duda importante, pero la tarea de identificarlos y obtenerlos va a ser para un analista un reto permanente. 

Como **primera parte** del estudio analítico que nos disponemos a realizar, se pide al estudiante que complete los siguientes pasos:   

1. Seleccionar un juego de datos y justificar su elección. El juego de datos deberá permitir resolver alguna pregunta analítica mediante la aplicación de algoritmos supervisados o no supervisados. El juego de datos deberá tener como mínimo 500 observaciones y debe ser distinto del usado en las PEC anteriores. El estudiante deberá visitar los siguientes portales de datos abiertos para seleccionar su juego de datos:

* **Datos abiertos**
  + [Google Dataset Search](https://datasetsearch.research.google.com/)
  + [Datos abiertos España](https://datos.gob.es/es/catalogo?q=&frequency=%7B"type"%3A+"months"%2C+"value"%3A+"1"%7D&sort=score+desc%2C+metadata_modified+desc)
  + [Datos abiertos Madrid](https://datos.madrid.es/portal/site/egob/)
  + [Datos abiertos Barcelona](https://opendata-ajuntament.barcelona.cat/es/)
  + [Datos abiertos Londres](https://data.london.gov.uk/)
  + [Datos abiertos New York](https://opendata.cityofnewyork.us/)
  
* **Conjuntos de datos para aprendizaje automático e investigación**
  + [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets.php)
  + [Datasets for machine-learning research (Wikipedia)](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)
  + [Kaggle datasets](https://www.kaggle.com/datasets)
  
Algún ejemplo del tipo de datos y problemas que podrían elegirse:

[Aprobación de tarjetas de crédito](https://www.kaggle.com/rikdifos/credit-card-approval-prediction) Una tarea de clasificación binaria para predecir si las personas pueden presentar un riesgo de incumplimiento de préstamos de tarjetas de crédito.

[Ventas de comercio electrónico](https://www.kaggle.com/carrie1/ecommerce-data): Predicción de ventas y transacciones en una tienda online. Un problema clásico de predicción de series temporales. 

Debéis tener en cuenta que deberéis usar este mismo conjunto de datos, una vez procesado y acondicionado, en los ejercicios de modelado dedatos de la segunda parte de la práctica (PRA2).

2. Plantear un problema de analítica de datos sobre el conjunto de datos seleccionado, detallando los objetivos analíticos y desarrollando una metodología para resolverlos de acuerdo con lo que se ha practicado en las PEC y lo que se ha aprendido en el material didáctico.

3. Realizar un análisis exploratorio del juego de datos seleccionado, utilizando las visualizaciones que crea necesrias para ilustrar su análisis.   

4. Realizar las tareas de limpieza y acondicionado necesarias para que los datos puedan ser usados en los consiguientes procesos de modelado.

5. Analizar las diferentes variables y realizar las transformaciones necesarias para la optimización de los procesos de modelado.

6. Realizar un análisis de componentes principales (PCA) o descomposición de valores singulares (SVD) sobre el juego de datos explicando los aspectos más destacados del análisis. Utilizar las componentes obtenidas para visualizar el conjunto de datos, y en su caso, poeéis usar las componentes como variables en el proceso de modelado. Se valorará si además profundizais en alguna otra técnica explicada en el módulo docente de **Preprocesado y gestión de características**.


## Recursos

### Recursos Básicos
Material docente proporcionado por la UOC. 

### Recursos de programación

* Incluimos en este apartado una lista de recursos de programación para minería de datos donde podréis encontrar ejemplos, ideas e inspiración:
  + [Material adicional del libro: Minería de datos Modelos y Algoritmos](http://oer.uoc.edu/libroMD/)
  + [Espacio de recursos UOC para ciencia de datos](http://datascience.recursos.uoc.edu/es/)
  + [Buscador de código R](https://rseek.org/)  
  + [Colección de cheatsheets en R](https://rstudio.com/resources/cheatsheets/)  
  
## Criterios de valoración

Para todas las PRA es **necesario documentar** en cada apartado del ejercicio práctico que se ha hecho y como se ha hecho. Asimismo, todas las decisiones y conclusiones deberán ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. 

## Formato y fecha de entrega PRA1
El formato de entrega es: **usernameestudiant-PRA1.Rmd** y **usernameestudiant-PRA1.html** (o .pdf/.docx)  
Se debe entregar la PRA1 en el buzón de entregas del aula  

## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en que se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar donde se obtuvo y su estatus legal: si la obra esta protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra esta protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Desarrollo de la práctica
******

## Elección del conjunto de datos

## Exploración del conjunto de datos

````{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('plyr')) install.packages('plyr'); library('plyr')
````

Iniciamos la carga de los datos, para ello realizamos la lectura de un fichero csv con esímbolo separador de ";". Para obtener la ruta del fichero se utilizará la función file.choose() que nos devuelve la ruta completa del fichero y lo almacenaremos en una variable que denominaremos ruta_csv.

````{r echo=TRUE, message=FALSE, warning=FALSE}
ruta_csv <- "C:\\Users\\Jorge\\Documents\\Rstudio Workspace\\Minería de datos\\PRA1\\2021_Accidentalidad.csv"
accidentes <- read.csv2(ruta_csv,na.strings="NA", encoding = "UTF-8")
summary(accidentes)
str(accidentes)
````

Verificamos la estructura de datos obtenida de la carga.
````{r echo=TRUE, message=FALSE, warning=FALSE}
str(accidentes)
````

Vemos que tenemos 24464 registros referentes a los accidentes de tráfico de la Ciudad de Madrid y 17 variables que los caracterizan.

Para una mayor legibilidad de los datos modificaremos el nombre de la columna "X.U.FEFF.num_expediente" por "num_expediente".

````{r echo=TRUE, message=FALSE, warning=FALSE}
accidentes <- rename(accidentes, c(X.U.FEFF.num_expediente = "num_expediente"))
````

Las descripciones de las variables que caracterizan a la muestra de datos son:

* **num_expediente: ** número de expediente del accidente. Pueden existir varios registros con el mismo número de expediente debido a que forman parte del mismo accidente donde hay varios afectados
* **fecha:** fecha en la que se produce el accidente
* **hora:** hora en la que s eproduce el accidente
* **localizacion:** calle en la que se produce el accidente
* **numero:** número de la calle donde se produce el accidente
* **distrito:** distrito donde se produce el accidente
* **tipo_accidente:** corresponde al tipo de accidente, por ejemplo si es una colisión doble, colisión múltiple, atropello, etc.
* **estado_metereológico:** condiciones ambientales que se dan en el momento del siniestro
* **tipo_vehiculo:** tipo del vehículo afectado
* **tipo_persona:** tipo de persona vinculada al accidente, ya sea conductor, viajero, peatón o testigo.
* **rango_edad:** rango de edad de la persona afectada en el siniestro.
* **sexo:** sexo de la persona afectada.
* **lesividad:** gravedad de las lesiones producidas en el accidente.
* **coordenada_x_utm:** coordenada x donde se produce el siniestro.
* **coordenada_y_utm:** coordenada y donde se produce el siniestro.
* **positiva_alcohol:** test de alcoholemia realizado a la persona afectada.
* **positiva_droga:** test de drogas realizado a la persona afectada.





## Preprocesado y gestión de características



````{r echo=TRUE, message=FALSE, warning=FALSE}
colSums(is.na(accidentes))
colSums(accidentes == "")
colSums(accidentes == "NULL")

accidentes$lesividad[accidentes$lesividad == "" | accidentes$lesividad == " "] = 14
accidentes$lesividad[accidentes$lesividad == "NULL"] = 77
colSums(accidentes == "")
colSums(accidentes == "NULL")
table(accidentes$lesividad)

accidentes$grado_lesividad <- ""
accidentes$grado_lesividad[accidentes$lesividad == 1 | accidentes$lesividad == 2 | accidentes$lesividad == 5 | accidentes$lesividad == 6 | accidentes$lesividad == 7] <- "Leve"
accidentes$grado_lesividad[accidentes$lesividad == 3] <- "Grave"
accidentes$grado_lesividad[accidentes$lesividad == 4] <- "Mortal"
accidentes$grado_lesividad[accidentes$lesividad == 14] <- "Sin asistencia"
accidentes$grado_lesividad[accidentes$lesividad == 77] <- "Desconocido"
head(accidentes$grado_lesividad)

````

## Construcción de conjunto de datos final

******
# Criterios de evaluación
******
* 10%. Justificación de la elección del juego de datos donde se detalle el potencial analítico que se intuye. 
* 10% Se plantea un problema propio de minería de datos, se detallan los objetivos analíticos y se explica detalladamente el procedimiento para darles solución.
* 20%. Información extraída del análisis exploratorio. Distribuciones, correlaciones, anomalías ... 
* 20%. Explicación clara de cualquier tarea de limpieza, acondicionado o transformación que se realiza sobre los datos, justificando el motivo y mencionando las ventajas de la acción tomada.
* 20%. Se realiza un proceso de PCA o SVD donde se aprecia mediante explicaciones y comentarios que el estudiante entiende todos los pasos y se comenta extensamente el resultado final obtenido. Se usan las componentes obtenidas para apoyar el análisis propuesto.
* 20%. Se obtiene un conjunto de datos preparado y descrito adecuadamente, especificando las variables que se usarán en los procesos de modelado posterior, y como se aplicarán los métodos propuestos sobre ellas. 


  



