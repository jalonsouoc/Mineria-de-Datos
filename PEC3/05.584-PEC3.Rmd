---
title: 'Minería de datos: PEC3 - Clasificación con árboles de decisión'
author: 
date: "Noviembre 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

******
# Recursos básicos
******

Material didáctico de: Modelos Supervisados y Evaluación de Modelos.

Complementarios:

* Los descritos para la anterior PEC.
* Fichero titanic.csv.
* R package C5.0 (Decision Trees and Rule-Based Models): https://cran.r-project.org/web/packages/C50/index.html
* Fichero de "German Credit": credit.csv: https://www.kaggle.com/shravan3273/credit-approval

******
# Ejemplo ilustrativo
******

En este ejercicio vamos a seguir los pasos del ciclo de vida de un proyecto de minería de datos, para el caso de un algoritmo de clasificación y más concretamente un árbol de decisión. Primero y a modo de ejemplo sencillo lo haremos con el archivo titanic.csv, que se encuentra adjunto en el aula. Este archivo contiene un registro por cada pasajero que viajaba en el Titanic. En las variables se caracteriza si era hombre o mujer, adulto o menor (niño), en qué categoría viajaba o si era miembro de la tripulación.
Se mostrará un ejemplo sencillo de solución con estos datos pero los alumnos deberéis responder a las preguntas de la rúbrica para otro conjunto: German Credit. Para este conjunto, tomaréis como referencia la variable "default" que indica el impago de créditos.

**Objetivos:**

*	Estudiar los datos, por ejemplo: ¿Número de registros del fichero? ¿Distribuciones de valores por variables? ¿Hay campos mal informados o vacíos?
*	Preparar los datos. En este caso ya están en el formato correcto y no es necesario discretizar ni generar atributos nuevos. Hay que elegir cuáles son las variables que se utilizarán para construir el modelo y cuál es la variable que clasifica. En este caso la variable por la que clasificaremos es el campo de si el pasajero sobrevivia o no.
*	Instalar, si es necesario, el paquete C5.0  Se trata de una implementación más moderna del algoritmo ID3 de Quinlan. Tiene los principios teóricos del ID3 más la poda automática. Con este paquete generar un modelo de minería.
*	¿Cuál es la calidad del modelo?
*	Generar el árbol gráfico.
* Generar y extraer las reglas del modelo.
*	En función del modelo, el árbol y las reglas: ¿Cuál es el conocimiento que obtenemos?
*	Probar el modelo generado presentándole nuevos registros. ¿Clasifica suficientemente bien?

A continuación, se plantean los puntos a realizar en la PEC 3 y, tomando como ejemplo el conjunto de datos de Titanic, se obtendrán, a modo de ejemplo, algunos resultados que pretender servir a  modo de inspiración para los estudiantes.
Los estudiantes deberán utilizar el conjunto de datos de "German Credit Data" que se pueden conseguir en este enlace: https://www.kaggle.com/shravan3273/credit-approval
  
Revisión de los datos, extracción visual de información y preparación de los datos

Carga de los datos:

```{r message= FALSE, warning=FALSE}
data<-read.csv("./titanic.csv",header=T,sep=",")
attach(data)
```

## Análisis inicial

Empezaremos haciendo un breve análisis de los datos ya que nos interesa tener una idea general de los datos que disponemos. 

### Exploración de la base de datos

Primero calcularemos las dimensiones de nuestra base de datos y analizaremos qué tipos de atributos tenemos.

Para empezar, calculamos las dimensiones de la base de datos mediante la función dim(). Obtenemos que disponemos de 2201 registros o pasajeros (filas) y 4 variables (columnas). 

```{r}
dim(data)
```

¿Cuáles son esas variables? Gracias a la función str() sabemos que las cuatro variables son categóricas o  discretas, es decir, toman valores en un conjunto finito. La variable CLASS hace referencia a la clase en la que viajaban los pasajeros (1ª, 2ª, 3ª o crew), AGE determina si era adulto o niño (Adulto o Menor), la variable SEX si era hombre o mujer (Hombre o Mujer) y la última variable (SURVIVED) informa si el pasajero murió o sobrevivió en el accidente (Muere o Sobrevive).

```{r}
str(data)
```

Es de gran interés saber si tenemos muchos valores nulos (campos vacíos) y la distribución de valores por variables. Es por ello recomendable empezar el análisis con una visión general de las variables. Mostraremos para cada atributo la cantidad de valores perdidos mediante la función summary.  

```{r}
summary(data)
```

Como parte de la preparación de los datos, miraremos si hay valores missing.

```{r}
missing <- data[is.na(data),]
dim(missing)
```
Observamos fácilmente que no hay valores missing y, por tanto, no deberemos preparar los datos en este sentido. En caso de haberlos, habría que tomar decisiones para tratar los datos adecuadamente.

Disponemos por tanto de un data frame formado por cuatro variables categóricas sin valores nulos. 

### Visualización

Para un conocimiento mayor sobre los datos, tenemos a nuestro alcance unas herramientas muy valiosas: las herramientas de visualización. Para dichas visualizaciones, haremos uso de los paquetes ggplot2, gridExtra y grid de R. 

```{r}
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(ggpubr)){
    install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}

```

Siempre es importante analizar los datos que tenemos ya que las conclusiones dependerán de las características de la muestra.

```{r}
grid.newpage()
plotbyClass<-ggplot(data,aes(CLASS))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Class")
plotbyAge<-ggplot(data,aes(AGE))+geom_bar() +labs(x="Age", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Age")
plotbySex<-ggplot(data,aes(SEX))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Sex")
plotbySurvived<-ggplot(data,aes(SURVIVED))+geom_bar() +labs(x="Survived", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("SURVIVED")
grid.arrange(plotbyClass,plotbyAge,plotbySex,plotbySurvived,ncol=2)

```
Claramente vemos cómo es la muestra analizando la distribución de las variables disponibles. De cara a los informes, es mucho más interesante esta información que la obtenida en summary, que se puede usar para complementar.


Nos interesa describir la relación entre la supervivencia y cada uno de las variables mencionadas anteriormente. Para ello, por un lado graficaremos mediante diagramas de barras la cantidad de muertos y supervivientes según la clase en la que viajaban, la edad o el sexo. Por otro lado, para obtener los datos que estamos graficando utilizaremos el comando table para dos variables que nos proporciona una tabla de contingencia.

```{r}
grid.newpage()
plotbyClass<-ggplot(data,aes(CLASS,fill=SURVIVED))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Class")
plotbyAge<-ggplot(data,aes(AGE,fill=SURVIVED))+geom_bar() +labs(x="Age", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Age")
plotbySex<-ggplot(data,aes(SEX,fill=SURVIVED))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Sex")
grid.arrange(plotbyClass,plotbyAge,plotbySex,ncol=2)

```

De estos gráficos obtenemos información muy valiosa que complementamos con las tablas de contingencia (listadas abajo). Por un lado, la cantidad de pasajeros que sobrevivieron es similar en hombres y mujeres (hombres: 367 y mujeres 344). No, en cambio, si tenemos en cuenta el porcentaje respecto a su sexo. Es decir, pese a que la cantidad de mujeres y hombres que sobrevivieron es pareja, viajaban más hombres que mujeres (470 mujeres y 1731 hombres), por lo tanto, la tasa de muerte en hombres es muchísimo mayor (el 78,79% de los hombres murieron mientras que en mujeres ese porcentaje baja a 26,8%). 

En cuanto a la clase en la que viajaban, los pasajeros que viajaban en primera clase fueron los únicos que el porcentaje de supervivencia era mayor que el de mortalidad. El 62,46% de los viajeros de primera clase sobrevivió, el 41,4% de los que viajaban en segunda clase mientras que de los viajeros de tercera y de la tripulación solo sobrevivieron un 25,21% y 23,95% respectivamente. Para finalizar, destacamos que la presencia de pasajeros adultos era mucho mayor que la de los niños (2092 frente a 109) y que la tasa de supervivencia en niños fue mucho mayor (52,29% frente a 31,26%), no podemos obviar, en cambio, que los únicos niños que murieron fueron todos pasajeros de tercera clase (52 niños). 

```{r}
tabla_SST <- table(SEX, SURVIVED)
tabla_SST
prop.table(tabla_SST, margin = 1)
```

```{r}
tabla_SCT <- table(CLASS,SURVIVED)
tabla_SCT
prop.table(tabla_SCT, margin = 1)
```

```{r}
tabla_SAT <- table(AGE,SURVIVED)
tabla_SAT
prop.table(tabla_SAT, margin = 1) 
```

```{r}
tabla_SAT.byClass <- table(AGE,SURVIVED,CLASS)
tabla_SAT.byClass
```

### Test estadísticos de significancia

Los resultados anteriores muestran los datos de forma descriptiva, podemos añadir algún test estadístico para validar el grado de significancia de la relación. La librería "DescTools" nos permite instalarlo fácilmente.


```{r}
if(!require(DescTools)){
    install.packages('DescTools', repos='http://cran.us.r-project.org')
    library(DescTools)
}
```
```{r}
Phi(tabla_SST) 
CramerV(tabla_SST) 
```
```{r}
Phi(tabla_SAT) 
CramerV(tabla_SAT) 
```

```{r}
Phi(tabla_SCT) 
CramerV(tabla_SCT) 
```

Valores de la V de Cramér  (https://en.wikipedia.org/wiki/Cramér%27s_V) y Phi (https://en.wikipedia.org/wiki/Phi_coefficient) entre 0.1 y 0.3 nos indican que la asociación estadística es baja, y entre 0.3 y 0.5 se puede considerar una asociación media. Finalmente, si los valores fueran superiores a 0.5 (no es el caso), la asociación estadística entre las variables sería alta.
Como se puede apreciar, los valores de Phi y V coinciden. Esto ocurre en el contexto de analizar tablas de contingencia 2x2.

Una alternativa interesante a las barras de diagramas, es el plot de las tablas de contingencia. Obtenemos la misma información pero para algunos receptores puede resultar más visual.  

```{r}
par(mfrow=c(2,2))
plot(tabla_SCT, col = c("black","#008000"), main = "SURVIVED vs. CLASS")
plot(tabla_SAT, col = c("black","#008000"), main = "SURVIVED vs. AGE")
plot(tabla_SST, col = c("black","#008000"), main = "SURVIVED vs. SEX")
```

Nuestro objetivo es crear un árbol de decisión que permita analizar qué tipo de pasajero del Titanic tenía probabilidades de sobrevivir o no. Por lo tanto, la variable por la que clasificaremos es el campo de si el pasajero sobrevivió o no. De todas maneras, al imprimir las primeras (con head) y últimas 10 (con tail) filas nos damos cuenta de que los datos están ordenados.

```{r}
head(data,10)
tail(data,10)
```

Nos interesa "desordenarlos". Guardaremos los datos con el nuevo nombre como "data_random".

```{r}
set.seed(1)
data_random <- data[sample(nrow(data)),]
```

## Preparación de los datos para el modelo

Para la futura evaluación del árbol de decisión, es necesario dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba. El conjunto de entrenamiento es el subconjunto del conjunto original de datos utilizado para construir un primer modelo; y el conjunto de prueba, el subconjunto del conjunto original de datos utilizado para evaluar la calidad del modelo. 

Lo más correcto será utilizar un conjunto de datos diferente del que utilizamos para construir el árbol, es decir, un conjunto diferente del de entrenamiento. No hay ninguna proporción fijada con respecto al número relativo de componentes de cada subconjunto, pero la más utilizada acostumbra a ser 2/3 para el conjunto de entrenamiento y 1/3, para el conjunto de prueba. 

La variable por la que clasificaremos es el campo de si el pasajero sobrevivió o no, que está en la cuarta columna. De esta forma, tendremos un conjunto de datos para el entrenamiento y uno para la validación

```{r}
set.seed(666)
y <- data_random[,4] 
X <- data_random[,1:3] 
```


De forma dinámica podemos definir una forma de separar los datos en función de un parámetro, en este caso del "split_prop".
Definimos un parámetro que controla el split de forma dinámica en el test.

```{r}
split_prop <- 3 
max_split<-floor(nrow(X)/split_prop)
tr_limit <- nrow(X)-max_split
ts_limit <- nrow(X)-max_split+1

trainX <- X[1:tr_limit,]
trainy <- y[1:tr_limit]
testX <- X[ts_limit+1:nrow(X),]
testy <- y[ts_limit+1:nrow(X)]
```

En la segunda opción podemos crear directamente un rango utilizando el mismo parámetro anterior.

```{r}
split_prop <- 3 
indexes = sample(1:nrow(data), size=floor(((split_prop-1)/split_prop)*nrow(data)))
trainX<-X[indexes,]
trainy<-y[indexes]
testX<-X[-indexes,]
testy<-y[-indexes]
```

Después de una extracción aleatoria de casos es altamente recomendable efectuar un análisis de datos mínimo para asegurarnos de no obtener clasificadores sesgados por los valores que contiene cada muestra. En este caso, verificaremos que la proporción del supervivientes es más o menos constante en los dos conjuntos:

```{r}
summary(trainX);
summary(trainy)
summary(testX)
summary(testy)
```
Verificamos fácilmente que no hay diferencias graves que puedan sesgar las conclusiones.

## Creación del modelo, calidad del modelo y extracción de reglas

Se crea el árbol de decisión usando los datos de entrenamiento (no hay que olvidar que la variable outcome es de tipo factor):

```{r}
trainy = as.factor(trainy)
model <- C50::C5.0(trainX, trainy,rules=TRUE )
summary(model)
```

Errors muestra el número y porcentaje de casos mal clasificados en el subconjunto de entrenamiento. El árbol obtenido clasifica erróneamente 317 de los 1467 casos dados, una tasa de error del 21.6%.

A partir del árbol de decisión de dos hojas que hemos modelado, se pueden extraer las siguientes reglas de decisión (gracias a rules=TRUE podemos imprimir las reglas directamente):

SEX = "Hombre" → Muere. Validez: 78,1%

CLASS "1ª", "2ª" y AGE = "Menor" → Sobrevive. Validez: 95,5%

SEX = "Mujer" → Sobrevive. Validez: 74,7%

Por tanto, podemos concluir que el conocimiento extraído y cruzado con el análisis visual se resume en "las mujeres y los niños primero a excepción de que fueras de 3ª clase".

A continuación, mostramos el árbol obtenido.

```{r}
model <- C50::C5.0(trainX, trainy)
plot(model)
```


## Validación del modelo con los datos reservados
Una vez tenemos el modelo, podemos comprobar su calidad prediciendo la clase para los datos de prueba que nos hemos reservado al principio. 

```{r}
predicted_model <- predict( model, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))
```

Cuando hay pocas clases, la calidad de la predicción se puede analizar mediante una matriz de confusión que identifica los tipos de errores cometidos. 

```{r}
mat_conf<-table(testy,Predicted=predicted_model)
mat_conf
```

Otra manera de calcular el porcentaje de registros correctamente clasificados usando la matriz de confusión:

```{r}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```

Además, tenemos a nuestra disposición el paquete gmodels para obtener información más completa:

```{r}
if(!require(gmodels)){
    install.packages('gmodels', repos='http://cran.us.r-project.org')
    library(gmodels)
}
```

```{r}
CrossTable(testy, predicted_model,prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE,dnn = c('Reality', 'Prediction'))
```

## Prueba con una variación u otro enfoque algorítmico

En este apartado buscaremos probar con las variaciones que nos ofrece el paquete C5.0 para analizar cómo afectan a la creación de los árboles generados. Existen muchas posibles variaciones con otras funciones que podéis investigar. La idea es seguir con el enfoque de árboles de decisión explorando posibles opciones.
Una vez tengamos un método alternativo, debemos analizar cómo se modifica el árbol y cómo afecta a la capacidad predictiva en el conjunto de test.

A continuación, utilizamos otro enfoque para comparar los resultados: incorpora como novedad "adaptative boosting", basado en el trabajo Rob Schapire and Yoav Freund (1999). La idea de esta técnica es generar varios clasificadores, con sus correspondientes arboles de decisión y su ser de reglas. Cuando un nuevo caso va a ser clasificado, cada clasificador vota cual es la clase predicha. Los votos son sumados y determina la clase final.

```{r}
modelo2 <- C50::C5.0(trainX, trainy, trials = 10)
plot(modelo2)
```

En este caso, dada la simplicidad del conjunto de ejemplo, no se aprecian diferencias, pero aparecerán en datos de mayor complejidad y modificando el parámetro "trials" se puede intentar mejorar los resultados.

Vemos a continuación cómo son las predicciones del nuevo árbol:

```{r}
predicted_model2 <- predict( modelo2, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model2 == testy) / length(predicted_model2)))
```
Observamos como se modifica levemente la precisión del modelo a mejor.

```{r}
mat_conf<-table(testy,Predicted=predicted_model2)
mat_conf
```

Otra manera de calcular el porcentaje de registros correctamente clasificados usando la matriz de confusión:

```{r}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```

El algoritmo C5.0 incorpora algunas opciones para ver la importancia de las variables (ver documentación para los detalles entre los dos métodos):

```{r}
importancia_usage <- C50::C5imp(modelo2, metric = "usage")
importancia_splits <- C50::C5imp(modelo2, metric = "splits")
importancia_usage
importancia_splits
```
Curiosamente y aunque el conjunto de datos es muy sencillo, se aprecian diferencias en los métodos de importancia de las variables. Se recomienda en vuestro ejercicio mejorar la visualización de los resultados con la función ggplo2 o similar.

# Enunciado del ejercicio

Para el conjunto de datos German Credit, los alumnos deben completar aquí la solución a la PEC3 que consiste de los siguientes apartados. Notad que se detalla el contenido necesario para cada apartado en la Sección 4 (Rúbrica).


## Análisis descriptivo y de correlaciones

Reealizamos la carga de los datos

````{r}
data_credit <- read.csv("./credit.csv")
````

Observamos una muestra de los datos cargados para comprobar que la carga se ha realizado correctamente.

`````{r}
head(data_credit)
````

De este primer vistazo a los datos, debemso destavar que la unidad de dinero empleada en la muestra es el marco alemán en lugar al euro, lo que nos hace indicar que no es una muestra reciente.

Realizamos un análisis de los datos a modo general. En primer lugar obtenemos las dimensiones de la muestra de datos.

`````{r}
dim(data_credit)
````

Observamos que disponemos de 1000 registros y 21 variables que los caracterizan. Estas variables que caracterizan el conjunto de datos son:

* **checking_balance:** balance de cuenta de la persona contratante del prestamo
* **month_loan_duration:** meses de duración del prestamo.
* **credit_history:** historial de crédito.
* **purpose:** propósito del crédito.
* **amount:** importe del préstamo.
* **savings_balance:** balance de ahorros de la persona contratante del prestamo
* **employment_length:** duración del empleo de la persona contratante del prestamo
* **installment_rate:** porcentaje de la cuota respecto del total del préstamo solicitado
* **personal_status:** estado civil de la persona contratante del préstamo.
* **other_debtors:** otros deudores además del prestatario del dinero
* **residence_history:** historial de alojamientos.
* **property:** tipo de contrato de la propiedad.
* **age:** edad de la persona contratante del crédito.
* **installment_plan:** origen del préstamo.
* **housing:** alojamiento de la persona contratante
* **existing_credits:** existencia de otros créditos concedidos
* **default:** indica si se realiza un incumplimiento en el pago del préstamo 
* **dependents:** indica si la persona contratante tiene a alguien a su cargo.
* **telephone:** indica si el contratante posee número de teléfono
* **foreign_worker:** indica si es un trabajador extranjero
* **job:** trabajo de la persona contratante del crédito.

Vemos el tipo de dato de cada una de las variables.

````{r}
str(data_credit)
````

Podemos ver que la mayoría de las variables se reparten entre el tipo de dato cadena y el tipo de dato entero. Entre algunas de estas variables de tipo entero son variables dicotómicas que toman los valores 1 y 2. Más adelante realizaremos una transformación del tipo entero a tipo cadena para una mayor legibilidad de los datos


Observamos el resumen de cada una de las variables.

`````{r}
summary(data_credit)
````

Del resúmen podemos destacar las variables dicotómicas comentadas anteriormente debido a que s eobserva que algunas variables tienen el valor máximo en 2 y el mínimo en 1 comopueden ser las variables dependents y default. Podemos desracar que la mayoría de prestamos son e un monto pequeño ya que los tres primeros cuartiles abarcan la cantidad de 250 a 3972 marcos alemanes. Podemos observar también que la persona de más edad a la que se le ha concedido un prestamo es de 75ños y la más joven de 19 años

Comprobamos al existencia de valores perdidos en la muestra de datos.

`````{r}
colSums(is.na(data_credit))
colSums(data_credit == "")
````

Observamos que no existen valores perdidos por lo tanto no será necesario preparar los datos en este aspecto. Disponemos de un dataframe formado por 21 variables sin valores nulos. Debemos de reducir el número de variables de la muestra a aquellas que sean relevantes para predecir si se producirá un incumplimiento de pago del préstamo.

Con el fin de mejorar la visualización e interpretación de los datos se realizán una serie de modificaciones sobre las variables dicotómicas que se definen binarias con los valores 1 y 2, estableciendo el 1 como afirmación falsa y el 2 como afirmación verdadera. Las variables a sustituir son la variable dependents y la variable objetivo default. También dividiremos en rango las adedaes de las personas de forma que se agrupen en rangos de 10 años.


````{r}
data_credit$dependents_var <- ""
data_credit$default_var <- ""

for (i in 1:length(data_credit$dependents)) {
  data_credit$dependents_var[i] <- ifelse(data_credit$dependents[i] == 2 , "yes", "none")
  data_credit$default_var[i] <- ifelse(data_credit$default[i] == 2, "non-payment", "repaid")
}

data_credit$range_age <- cut(data_credit$age, breaks = c(10,20,30,40,50,60,70,80), labels = c("10-19", "20-29", "30-39","40-49","50-59","60-69","70-80"))
````

Pasaremos ahora a visualizar los datos de la muestra.

````{r}
grid.newpage()

# checking_balance
plotChecking <- ggplot(data_credit,aes(checking_balance))+geom_bar() +labs(x="checking balance", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("checking_balance")

#savings_balance
plotSavings <- ggplot(data_credit,aes(savings_balance))+geom_bar() +labs(x="savings balance", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("savings_balance")

#other_debtors
plotDebtors <- ggplot(data_credit,aes(other_debtors))+geom_bar() +labs(x="other debtors", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("other_debtors")

#credit_history
plotCredit <- ggplot(data_credit,aes(credit_history))+geom_bar() +labs(x="credit history", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("credit history")

grid.arrange(plotChecking,  plotSavings, plotDebtors, plotCredit, ncol=2)

````

De estos datos podemos destacar que la mayoría de balances de cuenta son desconocidos en el momento en que se conde el préstamo, sin embargo el balance de ahorros predominante es el inferior a 100 marcos alemanes. También podemos destacar que la mayor parte de personas contratantes no poseen otr deudor. Por último destacar que la mayoría de los creditos pedidos con anterioridad al actual fueron devueltos por las personas.


````{r}

grid.newpage()

# employment_lkength
plotEmployment <- ggplot(data_credit,aes(employment_length))+geom_bar() +labs(x="employment length", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("employment length")

# personal_status
plotPersonal <- ggplot(data_credit,aes(personal_status))+geom_bar() +labs(x="personal status", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("personal status")

# range_age
plotAge <- ggplot(data_credit,aes(range_age))+geom_bar() +labs(x="range  age", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("range age")

# dependents_var
plotDependents <- ggplot(data_credit,aes(dependents_var))+geom_bar() +labs(x="dependents", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("dependents")
grid.arrange(plotEmployment, plotPersonal, plotAge, plotDependents, ncol=2)

````

Podemos ver en este caso que la mayoría de contratantes poseían un empleo de una duración entre 1 y 4 años, también podemos ver que la mayoría de personas era hombres solteros y que la edad de la que más se pide préstamos es entre los 20 y 29 años. Por último destacar que la mayoría de personas no dsisponían de personas a su cargo.

````{r}
grid.newpage()

# housing
plotHousing <- ggplot(data_credit,aes(housing))+geom_bar() +labs(x="housing", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("housing")

# default_var
plotDefault <- ggplot(data_credit,aes(default_var))+geom_bar() +labs(x="default", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("default")

grid.arrange(plotHousing, plotDefault, ncol=2)

````

Por último podemos ver  que la mayoría de personas poseían casa propia y que la mayoría de préstamos fueron devueltos.

Mostramos la relación entre la variable default que es la que nos indica si se realiza incumplimientos del pago y algunas de las variables anteriores.

````{r}
table(data_credit$default)

grid.newpage()

# default by range_age
plotAge <- ggplot(data_credit,aes(range_age, fill=default_var))+geom_bar() +labs(x="range  age", y="cantidad")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("default by range age")

#default by other_debtors
plotDebtors <- ggplot(data_credit,aes(other_debtors,fill=default_var))+geom_bar() +labs(x="other_debtors", y="default")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("default by other debptors")

grid.arrange(plotAge, plotDebtors, ncol=1)

````

En este caso podemos observar que la mayor cantidad de impagos se obtiene en el rango de edad de 20 a 29 años, siendo también como vimos antes el rango de edad con mayor cantiodad de prestamos concediods. Hay que destacar que el reango de edad de 30 a 39 años tiene una cantidad de préstamos pagados similar a el rango de eedad de 20 a 29 años siendo reseñable ya que hay una mayor cantidad de préstamos concedidos para este último rango de edad.

También destacar que las personas que tneían otros deudores destaca que los avalados tienen una mayor cantidad de pre´stamos pagados y los co-solicitantes tienen una mayor cantidad de impagos.


````{r}
grid.newpage()

#default by personal_status
plotPersonal <- ggplot(data_credit,aes(personal_status,fill=default_var))+geom_bar() +labs(x="personal_status", y="default")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("default by personal status")

#default by credit_history
plotCredit <- ggplot(data_credit,aes(credit_history,fill=default_var))+geom_bar() +labs(x="credit_history", y="default")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("default by credit history")

grid.arrange(plotPersonal, plotCredit, ncol=1)
````

Por último destacar que tanto los diferentes estados civiles como los diferentes histórcios de creditos se reparten bastante homogeneamente entre cada uno de los diferentes grupos. Destacar también que para las mujeres nos e hace una distinción del estado civil a diferencia de los hombres que tienen los estados civiles de divorciado, casado y soltero.

## Primer árbol de decisión

Para el entrenamiento de los datos incialmente escogemos de todas las variabels que caracterizan nuestra muestra un subconjunto de ellas que hemos considerado las más importaqntes a la hora de saber si se puede conceder un préstamo o no, elegimos un total de 9 variables más la variable objetivo. Las variables seleccionadas son checking_balance, savings_balance, other_debtors, employment_length, personal_status, dependents_var, range_age, credit_history, housing y la variable objetivo default_var

````{r}
data_credit_model <- data_credit[,c("checking_balance", "savings_balance", "other_debtors", "employment_length", "personal_status", "dependents_var", "range_age", "credit_history", "housing", "default_var")]
````

Vemos una pequeña muestra de los datos seleccionados.

````{r}
head(data_credit_model)
````

Para la realización del modelo de árbol de decisión clasificaremos por la variable default_var que indica si se produjo un impago o no. Obtendremos dos conjuntos de datos uno para el entrenamiento del modelo  y uno para la validación de este. Para la muestra de entrenamiento emplearemos la proporción de 2/3 del conjunto de datos y para la muestra de testeo 1/3 del conjunto de los datos. Con el conjunto de entrenamiento construiremos el árbol de decisiones y con la muestra de testeo realizaremos la validación del árbl generado con el conjnunto de datos de entrenamiento.

En primer lugar dividimos el conjunto de datos en dos partes, en la primera parte obtendremos los datos sin la variable objetivo y en el segundo conjunto sólo dispondremos de la variable a evaluar.

`````{r}
y <-  data_credit_model[,10]
x <- data_credit_model[,1:9]

````

Realizamos la división del conjunto de datos en la muestra de entrenamiento y de validación. Realizaremos esta operación tanto con la muestra con la variable objetivo como con la muestra con el resto de variables.


`````{r}

split_prop <- 3
max_split <- floor(nrow(x)/split_prop)
# límite superior de la muestra de entrenamiento 
tr_limit <- nrow(x) - max_split

#límite inferior de la muestra de validación
ts_limit <- nrow(x) - max_split + 1

# Muestra de entrenamiento 
train_x <- x[1:tr_limit,]
train_y <- y[1:tr_limit]

# Muestra de testeo
test_x <- x[ts_limit:nrow(x),]
test_y <- y[ts_limit:nrow(x)]
````

Mostramos un resumen de cada uno de los subconjuntos de datos para comprobar que no ha habido ningún error.

````{r}
summary(train_x)
summary(train_y)
summary(test_x)
summary(test_y)
````

Creamos el árbol de decisión usando los datos de entrenamiento. Convertimos la variable objetivo a tipo factor para que funcione correctmaente.

`````{r}

train_y = as.factor(train_y)
model <- C50::C5.0(train_x, train_y, rules = TRUE)
````

Mostramos las reglas definidas por nuestro modelo

````{r}
summary(model)
````

Observamos que el árbol clasifica mla 145 registros de los 667 registros de la muestra de entrenamiento. Vemos que se han generado 12 reglas que explicaremos en el siguiente apartado.

Mostramos ahora el árbol d decisión resultante

````{r, warning= FALSE}

model <- C50::C5.0(train_x, train_y)
plot(model, unifrom = TRUE)
````

## Explicación de las reglas obtenidas

En el modelo realizado en el apartado anterior hemos obtenido un total de 12 reglas, explicamos ahora cada una de ellas.

* Regla 1:


````
## Rule 1: (6, lift 2.9)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {unknown, 101 - 500 DM}
##  personal_status = married male
##  credit_history = repaid
##  ->  class non-payment  [0.875]
## 
````

Esta primera regla nos predice que los hombres casados con un balance de cuenta menor de 200 marcos alemanes, con un balance de ahorros entre 101 y 500 marcos alemanes y con un historial de crédito pagados realizará un impago.

* Regla 2

````
## Rule 2: (9/1, lift 2.7)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  personal_status = female
##  range_age = 30-39
##  credit_history in {repaid, delayed}
##  housing in {own, for free}
##  ->  class non-payment  [0.818]

Esta segunda regla nos establece que las mujeres entre 30 y 39 años con un balance de cuenta menor de 200 marcos alemanes con un historico de créditos pagados o atrasados y con casa propia o gratis realizarán un impago.
````

* Regla 3:

````
## Rule 3: (11/2, lift 2.5)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {< 100 DM, 101 - 500 DM}
##  other_debtors = none
##  employment_length in {4 - 7 yrs, 0 - 1 yrs}
##  personal_status = married male
##  credit_history in {repaid, delayed}
##  ->  class non-payment  [0.769]
````

Esta tercera regla establece que los hombres casados, sin otros deudores, con un balance de cuenta menor de 200 marcos alemanes y un balance de ahorros menor de 500 marcos alemanes, con una duración de empleo de 4 a 7 años o menor de 1 año y con un historial de crédito pagado o atrasado realizará un impago.

* Regla 4:

````
## Rule 4: (6/1, lift 2.5)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {unknown, < 100 DM, 101 - 500 DM}
##  other_debtors = none
##  range_age = 10-19
##  ->  class non-payment  [0.750]
````

Esta cuarta regla indica que las personas en el rango de edad de 10 a 19 años, con un balance en cuenta menor de 200 marcos alemanes y un balance de ahorros de 500 marcos alemanes y sin otros deudores realizará un impago.

* Regla 5:

````
## Rule 5: (43/12, lift 2.3)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  credit_history in {fully repaid, fully repaid this bank}
##  ->  class non-payment  [0.711]
````

Esta quinta regla establece que cualquier persona con un balance en cuenta menor de 200 marcos alemanes, aunque haya paga compeltamente sus deudas anteriores realizará un impago.

* Regla 6:

````
## Rule 6: (19/6, lift 2.2)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {unknown, < 100 DM, 101 - 500 DM}
##  other_debtors = none
##  personal_status = divorced male
##  ->  class non-payment  [0.667]
````
La sexta regla establece que los hombres divorciados con un balance en cuenta menor a 200 marcos alemanes y un balance de ahorros menor de 500 marcos alemanes y sin otros deudores realizará un impago.

* Regla 7:

````
## Rule 7: (39/13, lift 2.2)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {unknown, < 100 DM, 101 - 500 DM}
##  other_debtors = none
##  personal_status = female
##  range_age = 20-29
##  credit_history = repaid
##  ->  class non-payment  [0.659]
````
 La séptima regla establece que las mujeres de 20 a 29 años, con un historial de crédito de pagados, sin otros deudores pero con un balance en cuenta menor de 200 marcos alemanes y un balance de ahorros menor de 500 marcos alemanes realizará un impago del préstamo.


* Regla 8:

````
## Rule 8: (16/6, lift 2.0)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  other_debtors = co-applicant
##  credit_history in {critical, repaid, delayed}
##  ->  class non-payment  [0.611]
````

La octava regla dice que aquellos contratantes que tienen otros deudores ya que son co-solicitantes, con un historial de crédito pagado, atrasado y crítico, con un balance en cuenta menor de 200 marcos alemanes realizará un impago de la deuda.

* Regla 9:

```
## Rule 9: (197/98, lift 1.6)
##  checking_balance in {< 0 DM, 1 - 200 DM}
##  savings_balance in {unknown, < 100 DM, 101 - 500 DM}
##  other_debtors = none
##  credit_history in {repaid, delayed}
##  ->  class non-payment  [0.503]`

````


Esta novena regla nos dice que aquellos contratantes sin otros deudores, con un historial de crédito pagado o atrasado, con un balance en cuenta menor de 200 marcos alemanes y con un balance de ahorro menor de 500 marcos alemanes realizará un impago del préstamo concedido.

* Regla 10:

````
## Rule 10: (298/40, lift 1.2)
##  checking_balance in {unknown, > 200 DM}
##  ->  class repaid  [0.863]
````

Esta regla nos indica que aquellas personas con un balance en cuenta superior a 200 marcos alemanes pagará correctamente su deuda.

* Regla 11:

````
## Rule 11: (31/5, lift 1.2)
##  other_debtors = guarantor
##  credit_history in {critical, repaid}
##  ->  class repaid  [0.818]
````

Esta regla nos indica que las personas con otro deudor avalado y con un histórico de crédito crítico o pagado cumplirá con el pago de la deuda.
 
* Regla 12:

````
## Rule 12: (552/151, lift 1.0)
##  other_debtors = none
##  credit_history in {critical, repaid, delayed}
##  ->  class repaid  [0.726]
## 
````
Esta última regla nos indica que aquella spersonas que no poseen otros dudores y con un histórico de deuda pagado, crítco o atrasado cumplirá con la devolución del préstamo.


De todas las reglas podríamos destacar que hay dos variables importantes, y son prncipalmente el balance en cuenta, ya que la mayoría de impagos se produce cuando el contratante posee un balance menor a 200 marcos alemanes, por otro lado también destaca el balance ed ahorros, ya que principalmente se produce el impago en aquellas personas con un balance de ahorro menor a 500 marcos alemanes.

## Análisis de la bondad de ajuste sobre el conjunto de test y matriz de confusión

Una vez obtenido el modelo vamos comprobar su calidad prediciendo la clase para la muestra de testeo que separamos de los datos de entrenamiento al principio.

````{r}
predicted_model <- predict(model, test_x, type="class")
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == test_y) / length(predicted_model)))
````

Observamos que para la muestra de testeo el modelo acietta en un 71.17% de los casos.

Mostramos la matrix de confusión para identificar los tipos de errores cometidos.

````{r}
mat_conf <- table(test_y, Predicted=predicted_model)
mat_conf
````

Observamos que el princiapl error se comete en los impagos ya que clasifica más registros impagados como pagados. 

Mostramos más información acerca de los errores.


````{r}
CrossTable(test_y, predicted_model,prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE,dnn = c('Reality', 'Prediction'))
````


## Modelos complementarios

### RPART 
En primer lugar emplearemos la tecnica RPART o Recursive Partitioning and Regression Trees mediante la librería con el mismo nombre rpart

Cargamos la nueva librería.

````{r, echo=FALSE, warning=FALSE}
if (!require('rpart')) install.packages('rpart'); library('rpart')
if (!require('rpart.plot')) install.packages('rpart.plot'); library('rpart.plot')
````

Para este caso no vamos a distinguir dos conjuntos de datos uno con la variable objetivo y otro con el resto de variables. Sin embargo si que obtenemos un conjunto de datos de entrenamiento y otro de testeo con los mismos criterios empleados anteriormente.

````{r}
#Muestra de entrenamiento
train <- data_credit_model[1:tr_limit,]
# Muestra de testeo
test <- data_credit_model[ts_limit:nrow(data_credit_model),]
````

Obtenemos el modelo aplicando la nueva técnica y visualizamos el árbol de decisiones.

````{r}
model2 <- rpart(formula = default_var~., data = train, method="class" )
rpart.plot(model2)
````

Evaluamos el modelo obtenido mediante el conjunto de datos de testeo.

````{r}
predicted_model2 <- predict(model2, newdata = test, type="class")
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model2 == test$default_var) / length(predicted_model)))
````

Observamos que para la muestra de testeo el modelo acietta en un 70.87% de los casos. Podemos comprobar que es un porcentaje un poco inferior al modelo obtenido en los apartados anteriores.

Mostramos la matriz de confusión para identificar los tipos de errores cometidos.

````{r}
mat_conf <- table(test$default_var, Predicted=predicted_model2)
mat_conf
````

Podemos observar que esta técnica s ee quivoca más en la clasificación de préstamos pagadfos, ya que clasifica un mayor número de préstamos pagados como impagados.

### C50 Adaptative boosting

En este caso aplicaremos la mísma técnica empleada durante la prácita C50, pero añadiendo adaptative boosting. Realizamos el nuevo modelo aplicando el cambio. Emplearemos los mismos conjuntos de datos obtenidos para el primer árbol de decisiones obtenido durante la práctica.

````{r, warning = FALSE}
model3 <- C50::C5.0(train_x, train_y, trials = 10, Rules=TRUE)
summary(model3)

model3 <- C50::C5.0(train_x, train_y, trials = 10)
plot(model3)
````

Evaluamos el modelo obtenido mediante el conjunto de datos de testeo.

`````{r}
predicted_model <- predict(model3, test_x, type="class")
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == test_y) / length(predicted_model)))
````

Para este modelo observamos que la muestra de testeo acierta en un 70.57% de los casos. Comprobamos que es el menor porcentaje de acierto de los 3 modelos

Mostramos la matriz de confusión para identificar los tipos de errores cometidos.

````{r}
mat_conf <- table(test_y, Predicted=predicted_model)
mat_conf
````

Observamos que este modelo tiene un mayor número de erroes al clasificar los pagos como impagos.

## Conclusiones obtenidas

Hemos realizado varios modelos de ároles de decisiones empleando diferentes técnicas, se han utilizado el C50, el RPART y el C50 añadiendo Adaptative boosting. Los porcentajes de aciertto en cada técnica son:
* C50: 71.17%
* RPART: 70.87%
* C50 Adaptative boosting: 70.57%

Siendo el de mejor porcentaje de acierto el C50.

De este estudio obtenemos que hay dos variables importantes a la hora de impagos en los préstamos y son las variables checking_balance y saving_balance, realizandose la mayor parte de impagos cuando el valor del balance de cuenta es inferior a 200 y el balance de ahorros es inferior a 500, por otra parte cuando se posee un balance de cuenta superior a los 200 se realiza la devolución del pago correctamente.

******
# Rúbrica
******
* (Obligatorio) Se debe realizar un breve informe (PDF, Html.... ) donde se respondan a las preguntas concretas, mostrando en primer lugar el código utilizado, luego los resultados y posteriormente los comentarios que se consideren pertinentes para cada apartado.  
* 10% Hay un estudio sobre los datos de los que se parte, las variables que componen los datos. Los datos son preparados correctamente.
* 10% Se realiza un análisis descriptivo univariante (o análisis de relevancia) de algunas variables una vez se han tratado vs el target a nivel gráfico, comentando las que aparentemente son más interesantes. Análogamente se realiza un análisis de correlaciones.
* 20% Se aplica un árbol de decisión de forma correcta y se obtiene una estimación del error, mostrando gráficamente el árbol obtenido. La visualización debe ser comprensible y adecuada al problema a resolver.
* 15% Se explican las reglas que se obtienen en términos concretos del problema a resolver.
* 15% Se usa el modelo para predecir con muestras no usadas en el entrenamiento (holdout) y se obtiene una estimación del error. En base a la matriz de confusión, se comentan los tipos de errores y se valora de forma adecuada la capacidad predictiva del algoritmo.
* 15% Se prueba otro modelo de árbol o variantes diferentes del C50 y se comparan los resultados obtenidos, valorando si son mejores.
* 10% Con los resultados obtenidos anteriormente, se presentan unas conclusiones donde se expone un resumen de los diferentes modelos utilizados (al menos 3) así como el conocimiento adquirido tras el trabajo realizado y los descubrimientos más importantes realizados en el conjunto de datos.
* 5% Se presenta el código y es fácilmente reproducible.

